{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48e2fd3a",
   "metadata": {},
   "source": [
    "# Glassdoor Job Scraper \n",
    "#### Steps:\n",
    "* Import packages\n",
    "* Create URL list\n",
    "* Create beautiful soup objects\n",
    "* Iterate through each soup object to extract job info\n",
    "* Combine all job info into a data frame\n",
    "* Create counts for requested skills from job descriptions\n",
    "* Plot the relative frequency of top skills\n",
    "* Plot frequency of top companies\n",
    "* Plot frequency of top locations \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c724a81",
   "metadata": {},
   "source": [
    "#### Import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ea99b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28c20074",
   "metadata": {},
   "source": [
    "Define a list of urls to visit to scrape job data from. These are the first 5 pages of results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e985d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\"}\n",
    "\n",
    "paginationUrlList = ['https://www.glassdoor.com/Job/seattle-data-analyst-jobs-SRCH_IL.0,7_IC1150505_KO8,20.htm?suggestCount=0&suggestChosen=false&clickSource=searchBtn&typedKeyword=data%2520analyst', \n",
    "                      'https://www.glassdoor.com/Job/seattle-data-analyst-jobs-SRCH_IL.0,7_IC1150505_KO8,20_IP2.htm?includeNoSalaryJobs=true&pgc=AB4AAYEAHgAAAAAAAAAAAAAAAfIkpUYAMQEBAQgAobqqabHThiH41Zd%2FV0ZskPNB3AxbpQX5LppJCuB3fomVwkRwAv2DkPAwgk4AAA%3D%3D',\n",
    "                      'https://www.glassdoor.com/Job/seattle-data-analyst-jobs-SRCH_IL.0,7_IC1150505_KO8,20_IP3.htm?includeNoSalaryJobs=true&pgc=AB4AAoEAPAAAAAAAAAAAAAAAAfIkpUYASQEBARILjMiEUAfjSESQFv%2FS0H17lQf8k8MaNuVr77z1LxSPBs3RHQJvI8Vdbto2PuhBitPeY4eE0end%2BSxjib83fskVh1jbFUIAAA%3D%3D',\n",
    "                      'https://www.glassdoor.com/Job/seattle-data-analyst-jobs-SRCH_IL.0,7_IC1150505_KO8,20_IP4.htm?includeNoSalaryJobs=true&pgc=AB4AA4EAWgAAAAAAAAAAAAAAAfIkpUYAXAEDARQqCRQGF4%2F%2BcYvyRzvUf6RaBgmTEaN0izoiGel%2FMbiV7%2Faapz3IRBnvNyIt06JcBB%2BT6WDnL7y3DbOnJ4vSBVurBbme59Yg2fHn6OdyNtPMrK2WpwV%2BYx8dAAA%3D',\n",
    "                      'https://www.glassdoor.com/Job/seattle-data-analyst-jobs-SRCH_IL.0,7_IC1150505_KO8,20_IP5.htm?includeNoSalaryJobs=true&pgc=AB4ABIEAeAAAAAAAAAAAAAAAAfIkpUYAXgEBASYSJI8%2FuqWcmYtLOSVFYozfvOsM%2F06tYAXewKJnlNejOmLsl%2Bs5%2F4ZoFqsusqH2smmfEauzWkjAZ449oqDlkDxrCW82wXLsbxJQR3AT4g8X1y41uhWcwFFdIdoAAA%3D%3D']\n",
    "                      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35028072",
   "metadata": {},
   "source": [
    "Create a BeautifulSoup object for each url in the list of job results pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf54189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginationSoupList = []\n",
    "for url in paginationUrlList:\n",
    "    response = requests.get(url, headers = headers)\n",
    "    paginationSoup = BeautifulSoup(response.text, 'html.parser')\n",
    "    paginationSoupList.append(paginationSoup)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d570b127",
   "metadata": {},
   "source": [
    "Parse BeautifulSoup objects to extract job titles, companies, locations, job descriptions, and salary info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa7bd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobUrlTemplate = \"https://www.glassdoor.com{}\" # for use in navigating to each jobUrl to get job description\n",
    "\n",
    "pageCompanyList = []\n",
    "pageLocationList = []\n",
    "pageSalaryList = []\n",
    "pageTitleList = []\n",
    "\n",
    "pageDescriptionList = []\n",
    "pageQualificationsList = []\n",
    "\n",
    "for soup in paginationSoupList:\n",
    "    \n",
    "    #print(soup.prettify()) # Need to increase ipython console line limit to read all of it when you use prettify()\n",
    "    \n",
    "    companyResults = soup.find_all('td', attrs = {'class': 'company'})\n",
    "    locationResults = soup.find_all('td', attrs = {'class': 'location'})\n",
    "    jobResults = soup.find_all('td', attrs = {'class': 'job_title'})\n",
    "    \n",
    "    companyList = []\n",
    "    for tag in companyResults:\n",
    "        companyList.append(tag.text.lower().strip())\n",
    "    \n",
    "    locationList = []\n",
    "    for tag in locationResults:\n",
    "        locationList.append(tag.text.lower().strip())\n",
    "\n",
    "    jobTitleList = []\n",
    "    for tag in jobResults: \n",
    "        jobTag = tag.find('a')    \n",
    "        jobTitle = jobTag.text\n",
    "        jobTitleList.append(jobTitle.lower().strip())\n",
    "\n",
    "    pageCompanyList.append(companyList) # !!!! - LIST OF LIST\n",
    "    pageLocationList.append(locationList) # !!!! - LIST OF LIST \n",
    "    pageTitleList.append(jobTitleList) # !!!! - LIST OF LIST \n",
    "\n",
    "    # Collect urls for each job, in order to view the job description for each job\n",
    "    jobUrlList = []\n",
    "    for tag in jobResults:\n",
    "        jobTag = tag.find('a')\n",
    "        jobUrl = jobUrlTemplate.format(jobTag['href']) # adds the suffix for the specific job onto the base www.glassdoor.com url \n",
    "        jobUrlList.append(jobUrl)\n",
    "\n",
    "    # Iterate through each job url and extract job description and salary data\n",
    "    jobDescriptionList = []\n",
    "    salaryList = []\n",
    "    for url in jobUrlList:\n",
    "        jobPage = requests.get(url, headers = headers)\n",
    "        jobPageSoup = BeautifulSoup(jobPage.text, 'html.parser')\n",
    "        #print(jobPageSoup.prettify())\n",
    "        salaryTag = jobPageSoup.find('span', attrs = {'class' : 'small css-10zcshf e1v3ed7e1'})\n",
    "        #print(salaryTag)\n",
    "        try:\n",
    "            salary = salaryTag.text.strip() \n",
    "        except:\n",
    "            print('No salary info')\n",
    "            salary = 'NO SALARY INFO'\n",
    "            \n",
    "        try:\n",
    "            descriptionTag = jobPageSoup.find_all('div', attrs = {'id': 'JobDescriptionContainer'})\n",
    "            description = descriptionTag[0].text\n",
    "        except:\n",
    "            print('skipping page, no job description')\n",
    "            description = 'NO DESCRIPTION FOUND'\n",
    "        jobDescriptionList.append(description)\n",
    "        salaryList.append(salary)\n",
    "    \n",
    "    pageSalaryList.append(salaryList)\n",
    "    pageDescriptionList.append(jobDescriptionList) # !!!! - LIST OF LIST\n",
    "    \n",
    "    #key words to look for: Skills, Education, Experience, requirements, qualifications\n",
    "    keyWords = ['experience', 'requirements', 'qualifications']\n",
    "    \n",
    "    # Extract the Job qualifications from each job description\n",
    "    jobQualificationsList = []\n",
    "    for jobDescription in jobDescriptionList:\n",
    "        jobDescription = jobDescription.lower().strip() # convert to lowercase for easier matching\n",
    "        found = False\n",
    "        for word in keyWords:\n",
    "            location = jobDescription.find(word)\n",
    "            if location != -1:\n",
    "                found = True\n",
    "                jobQualifications = jobDescription[location:]\n",
    "                break # can break out of loop once one of the words is found\n",
    "        if not found: \n",
    "            jobQualifications = 'QUALIFICATIONS NOT FOUND'\n",
    "        jobQualificationsList.append(jobQualifications)\n",
    "        \n",
    "    pageQualificationsList.append(jobQualificationsList) # !!!! - LIST OF LIST\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b86ebe26",
   "metadata": {},
   "source": [
    "Flatten the lists of lists that contain info for each page into flat lists that countain info for all the jobs (eg. fullTitleList is a list of all the job titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289af385",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullQualificationsList = [q for sublist in pageQualificationsList for q in sublist]\n",
    "fullTitleList = [q for sublist in pageTitleList for q in sublist]\n",
    "fullCompanyList = [q for sublist in pageCompanyList for q in sublist]\n",
    "fullLocationList = [q for sublist in pageLocationList for q in sublist]\n",
    "fullDescriptionList = [q for sublist in pageDescriptionList for q in sublist]\n",
    "fullSalaryList = [q for sublist in pageSalaryList for q in sublist]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5daa0e88",
   "metadata": {},
   "source": [
    "Create a dataframe from these lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af10296",
   "metadata": {},
   "outputs": [],
   "source": [
    "qualificationsList = pd.DataFrame(fullQualificationsList)\n",
    "titleList = pd.DataFrame(fullTitleList)\n",
    "companyList = pd.DataFrame(fullCompanyList)\n",
    "locationList = pd.DataFrame(fullLocationList)\n",
    "descriptionList = pd.DataFrame(fullDescriptionList)\n",
    "salaryList = pd.DataFrame(fullSalaryList)\n",
    "\n",
    "df = pd.concat([titleList, companyList, locationList, salaryList, qualificationsList, descriptionList], axis = 1)\n",
    "df.columns = ['Job Title', 'Company', 'Location', 'Salary', 'Qualifications', 'Full Description']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dedfc148",
   "metadata": {},
   "source": [
    "Save the dataframe to a csv file to be loaded for analysis in 'Glassdoor_analysis.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d912b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"C:/Users/micha/Desktop/Python Projects/glassdoor.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b239acf2821489c398a9848859e84ce39b99d30cc4031fb37cc7461da3883639"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
